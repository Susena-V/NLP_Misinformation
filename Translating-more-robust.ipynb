{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9727582,"sourceType":"datasetVersion","datasetId":5952474},{"sourceId":10773805,"sourceType":"datasetVersion","datasetId":6667175}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:05.453445Z","iopub.execute_input":"2025-02-17T13:32:05.453654Z","iopub.status.idle":"2025-02-17T13:32:07.552569Z","shell.execute_reply.started":"2025-02-17T13:32:05.453633Z","shell.execute_reply":"2025-02-17T13:32:07.551622Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/translated-and-cleaned-tweets/Cleaned_tweets.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.553434Z","iopub.execute_input":"2025-02-17T13:32:07.553802Z","iopub.status.idle":"2025-02-17T13:32:07.593824Z","shell.execute_reply.started":"2025-02-17T13:32:07.553779Z","shell.execute_reply":"2025-02-17T13:32:07.592893Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.595004Z","iopub.execute_input":"2025-02-17T13:32:07.595371Z","iopub.status.idle":"2025-02-17T13:32:07.643172Z","shell.execute_reply.started":"2025-02-17T13:32:07.595336Z","shell.execute_reply":"2025-02-17T13:32:07.642139Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0.1  Unnamed: 0                   ID  \\\n0               0           0  1498022438398877704   \n1               2           2  1497887473862467584   \n2               3           3  1497838543619645441   \n3               4           4  1497639979534667783   \n4               5           5  1497624763396546561   \n..            ...         ...                  ...   \n475           718         718  1538486694701408256   \n476           721         721  1538254178413322241   \n477           722         722  1537840889749458946   \n478           726         726  1535923240710946816   \n479           727         727  1535893068108513280   \n\n                                                   URL   Type  Label  \\\n0    https://twitter.com/manuela_carloni/status/149...  tweet      1   \n1    https://twitter.com/barbarameletto/status/1497...  tweet      2   \n2    https://twitter.com/_dani_ta_6/status/14978385...  tweet      2   \n3    https://twitter.com/GabrieleGranato/status/149...  tweet      2   \n4    https://twitter.com/nonleggerlo/status/1497624...  tweet      1   \n..                                                 ...    ...    ...   \n475  https://twitter.com/fratotolo2/status/15384866...  tweet      1   \n476  https://twitter.com/104Pierpa/status/153825417...  tweet      0   \n477  https://twitter.com/PartitComunista/status/153...  tweet      2   \n478  https://twitter.com/PartitComunista/status/153...  tweet      2   \n479  https://twitter.com/PartitComunista/status/153...  tweet      2   \n\n                                               Content  \\\n0    Dopo aver hackerato la tv di Stato sostituendo...   \n1    #flowers #lovers\\nFate l'amore non fate la gue...   \n2    Se solo tutti mostrassimo più amore e comprens...   \n3    Chi sono i soldati che vediamo nei video? Sono...   \n4    Non credevo che #Salvini potesse peggiorare la...   \n..                                                 ...   \n475  Se scrivo che la signora #Zelensky sarebbe sta...   \n476  #Zelensky e sua moglie #OlenaZelenska hanno ac...   \n477  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n478  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n479  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n\n                  Image_Name  \n0    1498022438398877704.jpg  \n1    1497887473862467584.jpg  \n2    1497838543619645441.jpg  \n3    1497639979534667783.jpg  \n4    1497624763396546561.jpg  \n..                       ...  \n475  1538486694701408256.jpg  \n476  1538254178413322241.jpg  \n477  1537840889749458946.jpg  \n478  1535923240710946816.jpg  \n479  1535893068108513280.jpg  \n\n[480 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>URL</th>\n      <th>Type</th>\n      <th>Label</th>\n      <th>Content</th>\n      <th>Image_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1498022438398877704</td>\n      <td>https://twitter.com/manuela_carloni/status/149...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Dopo aver hackerato la tv di Stato sostituendo...</td>\n      <td>1498022438398877704.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1497887473862467584</td>\n      <td>https://twitter.com/barbarameletto/status/1497...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>#flowers #lovers\\nFate l'amore non fate la gue...</td>\n      <td>1497887473862467584.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1497838543619645441</td>\n      <td>https://twitter.com/_dani_ta_6/status/14978385...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Se solo tutti mostrassimo più amore e comprens...</td>\n      <td>1497838543619645441.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1497639979534667783</td>\n      <td>https://twitter.com/GabrieleGranato/status/149...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Chi sono i soldati che vediamo nei video? Sono...</td>\n      <td>1497639979534667783.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1497624763396546561</td>\n      <td>https://twitter.com/nonleggerlo/status/1497624...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Non credevo che #Salvini potesse peggiorare la...</td>\n      <td>1497624763396546561.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>718</td>\n      <td>718</td>\n      <td>1538486694701408256</td>\n      <td>https://twitter.com/fratotolo2/status/15384866...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Se scrivo che la signora #Zelensky sarebbe sta...</td>\n      <td>1538486694701408256.jpg</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>721</td>\n      <td>721</td>\n      <td>1538254178413322241</td>\n      <td>https://twitter.com/104Pierpa/status/153825417...</td>\n      <td>tweet</td>\n      <td>0</td>\n      <td>#Zelensky e sua moglie #OlenaZelenska hanno ac...</td>\n      <td>1538254178413322241.jpg</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>722</td>\n      <td>722</td>\n      <td>1537840889749458946</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1537840889749458946.jpg</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>726</td>\n      <td>726</td>\n      <td>1535923240710946816</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535923240710946816.jpg</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>727</td>\n      <td>727</td>\n      <td>1535893068108513280</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535893068108513280.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def clean_text(text):\n    if isinstance(text, str):\n        # Remove URLs\n        text = re.sub(r\"https\\S+\", \"\", text)\n        text = re.sub(r\"http\\S+\", \"\", text)\n\n        return text\n    return \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.644335Z","iopub.execute_input":"2025-02-17T13:32:07.644706Z","iopub.status.idle":"2025-02-17T13:32:07.649409Z","shell.execute_reply.started":"2025-02-17T13:32:07.644670Z","shell.execute_reply":"2025-02-17T13:32:07.648552Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"cleaned_data = data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.650378Z","iopub.execute_input":"2025-02-17T13:32:07.650748Z","iopub.status.idle":"2025-02-17T13:32:07.666855Z","shell.execute_reply.started":"2025-02-17T13:32:07.650713Z","shell.execute_reply":"2025-02-17T13:32:07.665791Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"cleaned_data['Content'] = cleaned_data['Content'].apply(clean_text)\ncleaned_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.669113Z","iopub.execute_input":"2025-02-17T13:32:07.669419Z","iopub.status.idle":"2025-02-17T13:32:07.697155Z","shell.execute_reply.started":"2025-02-17T13:32:07.669390Z","shell.execute_reply":"2025-02-17T13:32:07.696152Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0.1  Unnamed: 0                   ID  \\\n0               0           0  1498022438398877704   \n1               2           2  1497887473862467584   \n2               3           3  1497838543619645441   \n3               4           4  1497639979534667783   \n4               5           5  1497624763396546561   \n..            ...         ...                  ...   \n475           718         718  1538486694701408256   \n476           721         721  1538254178413322241   \n477           722         722  1537840889749458946   \n478           726         726  1535923240710946816   \n479           727         727  1535893068108513280   \n\n                                                   URL   Type  Label  \\\n0    https://twitter.com/manuela_carloni/status/149...  tweet      1   \n1    https://twitter.com/barbarameletto/status/1497...  tweet      2   \n2    https://twitter.com/_dani_ta_6/status/14978385...  tweet      2   \n3    https://twitter.com/GabrieleGranato/status/149...  tweet      2   \n4    https://twitter.com/nonleggerlo/status/1497624...  tweet      1   \n..                                                 ...    ...    ...   \n475  https://twitter.com/fratotolo2/status/15384866...  tweet      1   \n476  https://twitter.com/104Pierpa/status/153825417...  tweet      0   \n477  https://twitter.com/PartitComunista/status/153...  tweet      2   \n478  https://twitter.com/PartitComunista/status/153...  tweet      2   \n479  https://twitter.com/PartitComunista/status/153...  tweet      2   \n\n                                               Content  \\\n0    Dopo aver hackerato la tv di Stato sostituendo...   \n1    #flowers #lovers\\nFate l'amore non fate la gue...   \n2    Se solo tutti mostrassimo più amore e comprens...   \n3    Chi sono i soldati che vediamo nei video? Sono...   \n4    Non credevo che #Salvini potesse peggiorare la...   \n..                                                 ...   \n475  Se scrivo che la signora #Zelensky sarebbe sta...   \n476  #Zelensky e sua moglie #OlenaZelenska hanno ac...   \n477  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n478  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n479  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n\n                  Image_Name  \n0    1498022438398877704.jpg  \n1    1497887473862467584.jpg  \n2    1497838543619645441.jpg  \n3    1497639979534667783.jpg  \n4    1497624763396546561.jpg  \n..                       ...  \n475  1538486694701408256.jpg  \n476  1538254178413322241.jpg  \n477  1537840889749458946.jpg  \n478  1535923240710946816.jpg  \n479  1535893068108513280.jpg  \n\n[480 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>URL</th>\n      <th>Type</th>\n      <th>Label</th>\n      <th>Content</th>\n      <th>Image_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1498022438398877704</td>\n      <td>https://twitter.com/manuela_carloni/status/149...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Dopo aver hackerato la tv di Stato sostituendo...</td>\n      <td>1498022438398877704.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1497887473862467584</td>\n      <td>https://twitter.com/barbarameletto/status/1497...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>#flowers #lovers\\nFate l'amore non fate la gue...</td>\n      <td>1497887473862467584.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1497838543619645441</td>\n      <td>https://twitter.com/_dani_ta_6/status/14978385...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Se solo tutti mostrassimo più amore e comprens...</td>\n      <td>1497838543619645441.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1497639979534667783</td>\n      <td>https://twitter.com/GabrieleGranato/status/149...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Chi sono i soldati che vediamo nei video? Sono...</td>\n      <td>1497639979534667783.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1497624763396546561</td>\n      <td>https://twitter.com/nonleggerlo/status/1497624...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Non credevo che #Salvini potesse peggiorare la...</td>\n      <td>1497624763396546561.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>718</td>\n      <td>718</td>\n      <td>1538486694701408256</td>\n      <td>https://twitter.com/fratotolo2/status/15384866...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Se scrivo che la signora #Zelensky sarebbe sta...</td>\n      <td>1538486694701408256.jpg</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>721</td>\n      <td>721</td>\n      <td>1538254178413322241</td>\n      <td>https://twitter.com/104Pierpa/status/153825417...</td>\n      <td>tweet</td>\n      <td>0</td>\n      <td>#Zelensky e sua moglie #OlenaZelenska hanno ac...</td>\n      <td>1538254178413322241.jpg</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>722</td>\n      <td>722</td>\n      <td>1537840889749458946</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1537840889749458946.jpg</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>726</td>\n      <td>726</td>\n      <td>1535923240710946816</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535923240710946816.jpg</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>727</td>\n      <td>727</td>\n      <td>1535893068108513280</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535893068108513280.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"cleaned_data.to_csv('Cleaned.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.698872Z","iopub.execute_input":"2025-02-17T13:32:07.699285Z","iopub.status.idle":"2025-02-17T13:32:07.730185Z","shell.execute_reply.started":"2025-02-17T13:32:07.699249Z","shell.execute_reply":"2025-02-17T13:32:07.729174Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Translation","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Prompt: \n\n<|im_start|>user\nTranslate the following text from Portuguese into English.\nPortuguese: Um grupo de investigadores lançou um novo modelo para tarefas relacionadas com tradução.\nEnglish:<|im_end|>\n<|im_start|>assistant\nA group of researchers has launched a new model for translation-related tasks.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/Cleaned.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.731053Z","iopub.execute_input":"2025-02-17T13:32:07.731301Z","iopub.status.idle":"2025-02-17T13:32:07.743172Z","shell.execute_reply.started":"2025-02-17T13:32:07.731282Z","shell.execute_reply":"2025-02-17T13:32:07.742207Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:07.744217Z","iopub.execute_input":"2025-02-17T13:32:07.744524Z","iopub.status.idle":"2025-02-17T13:32:46.578442Z","shell.execute_reply.started":"2025-02-17T13:32:07.744501Z","shell.execute_reply":"2025-02-17T13:32:46.577470Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-4cferhce\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-4cferhce\n  Resolved https://github.com/huggingface/transformers.git to commit 936aeb70abe14cfbc70fb4d4d0c7b1864a21cc54\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0.dev0) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0.dev0) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.49.0.dev0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.49.0.dev0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10770282 sha256=d957685761fdcc26df43a202896a83a3124f904739c1c279c24ecfb640e2d20c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u3z9l0bk/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed transformers-4.49.0.dev0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%pip install accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:46.579315Z","iopub.execute_input":"2025-02-17T13:32:46.579545Z","iopub.status.idle":"2025-02-17T13:32:50.442953Z","shell.execute_reply.started":"2025-02-17T13:32:46.579525Z","shell.execute_reply":"2025-02-17T13:32:50.441984Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.28.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Install transformers from source - only needed for versions <= v4.34\n# pip install git+https://github.com/huggingface/transformers.git\n# pip install accelerate\n\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"Unbabel/TowerInstruct-13B-v0.1\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n# We use the tokenizer’s chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\nmessages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\\nEnglish:\"},\n]\nprompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\noutputs = pipe(prompt, max_new_tokens=256, do_sample=False)\nprint(outputs[0][\"generated_text\"])\n\n# <|im_start|>user\n# Translate the following text from Italian into English.\n# Italian: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\n# English:<|im_end|>\n# <|im_start|>assistant\n# A group of researchers has launched a new model for translation-related tasks.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:32:50.444093Z","iopub.execute_input":"2025-02-17T13:32:50.444408Z","iopub.status.idle":"2025-02-17T13:59:17.583402Z","shell.execute_reply.started":"2025-02-17T13:32:50.444382Z","shell.execute_reply":"2025-02-17T13:59:17.582569Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfd179a971fc422488b1b7a7911f871d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/29.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c8519de22954398baadcaff591818d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ee1058266d24e2989c58e51e2889e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00011.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7ad8eaa278480995eb94d7591845bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b81abda5dca4d87b456f407fe23c6d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df7f72333a6748349f1f915ecb813f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86dda5236efa4680bb04fb347becf375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f2c62f19bed42ed9398416209a424af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00011.safetensors:   0%|          | 0.00/4.79G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e6358fdd584c399378fd3e3f179db5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00011.safetensors:   0%|          | 0.00/4.79G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6bcf6429f97400791635c610cc447cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00011.safetensors:   0%|          | 0.00/4.79G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ca3e84f6164dfb9eb003d0bf4b7ffe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00025f79d8464444982dabd9820e8cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459d6683adc4430e8f7fc8163d00342e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00011.safetensors:   0%|          | 0.00/2.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a559cb2377ae456daa42d6f68cf226ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c3a12ae586f48e18a2117492ec516d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217608050620499f818e61fb2f8d1ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46f7f9d471ed4c8ea84ec96817b90eba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ae7a482a7242f086cc8ada5ad0719e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00402366e8da491a917bf142a5653c1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac9b723ac9f437389608dd7d84ec05f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/974 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7df95fcc7374a37875b2753724b83bd"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>user\nTranslate the following text from Italian into English.\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\nEnglish:<|im_end|>\n<|im_start|>assistant\n A group of researchers has launched a new model for translation-related tasks.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # Should return True\nprint(torch.cuda.get_device_name(0))  # Should show \"Tesla T4\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T13:59:17.588399Z","iopub.execute_input":"2025-02-17T13:59:17.588635Z","iopub.status.idle":"2025-02-17T13:59:17.593877Z","shell.execute_reply.started":"2025-02-17T13:59:17.588613Z","shell.execute_reply":"2025-02-17T13:59:17.593219Z"}},"outputs":[{"name":"stdout","text":"True\nTesla T4\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\\nEnglish:\"},\n]\nprompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\noutputs = pipe(prompt, max_new_tokens=256, do_sample=False)\nprint(outputs[0][\"generated_text\"])\nprint(outputs[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:05:04.883176Z","iopub.execute_input":"2025-02-17T14:05:04.883480Z","iopub.status.idle":"2025-02-17T14:05:07.502986Z","shell.execute_reply.started":"2025-02-17T14:05:04.883456Z","shell.execute_reply":"2025-02-17T14:05:07.502338Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>user\nTranslate the following text from Italian into English.\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\nEnglish:<|im_end|>\n<|im_start|>assistant\n A group of researchers has launched a new model for translation-related tasks.\n{'generated_text': '<|im_start|>user\\nTranslate the following text from Italian into English.\\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\\nEnglish:<|im_end|>\\n<|im_start|>assistant\\n A group of researchers has launched a new model for translation-related tasks.'}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Define your messages and translation task\nmessages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n]\n\n# Define the text you want to translate\ntext = \"Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\"\n\n# Combine the messages and text in a column-wise format\nprompt = pipe.tokenizer.apply_chat_template(\n    messages + [{\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"}],\n    tokenize=False,\n    add_generation_prompt=True\n)\n\n# Generate the translation\noutputs = pipe(prompt, max_new_tokens=256, do_sample=False)\n\n# Print the result\nprint(outputs[0][\"generated_text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:05:51.991280Z","iopub.execute_input":"2025-02-17T14:05:51.991601Z","iopub.status.idle":"2025-02-17T14:05:54.635662Z","shell.execute_reply.started":"2025-02-17T14:05:51.991576Z","shell.execute_reply":"2025-02-17T14:05:54.634843Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>user\nTranslate the following text from Italian into English.<|im_end|>\n<|im_start|>user\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\nEnglish:<|im_end|>\n<|im_start|>assistant\n A group of researchers has launched a new model for translation-related tasks.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Define your messages and translation task\nmessages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n]\n\n# Define the text you want to translate\ntext = \"Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\"\n\n# Combine the messages and text in a column-wise format\nprompt = pipe.tokenizer.apply_chat_template(\n    messages + [{\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"}],\n    tokenize=False,\n    add_generation_prompt=True\n)\n\n# Generate the translation with Top-k sampling\noutputs = pipe(\n    prompt,\n    max_new_tokens=256,  # Max tokens to generate\n    do_sample=True,       # Enable sampling for randomness\n    top_k=1,             # Limit sampling to top 50 tokens\n)\n\n# Print the result\nprint(outputs[0][\"generated_text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:08:03.450005Z","iopub.execute_input":"2025-02-17T14:08:03.450312Z","iopub.status.idle":"2025-02-17T14:08:06.130637Z","shell.execute_reply.started":"2025-02-17T14:08:03.450289Z","shell.execute_reply":"2025-02-17T14:08:06.129961Z"}},"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>user\nTranslate the following text from Italian into English.<|im_end|>\n<|im_start|>user\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\nEnglish:<|im_end|>\n<|im_start|>assistant\n A group of researchers has launched a new model for translation-related tasks.\n<class 'str'>\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Define your messages and translation task\nmessages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n]\n\n# Define the text you want to translate\ntext = \"Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\"\n\n# Combine the messages and text in a column-wise format\nprompt = pipe.tokenizer.apply_chat_template(\n    messages + [{\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"}],\n    tokenize=False,\n    add_generation_prompt=True\n)\n\n# Generate the translation with Top-k sampling\noutputs = pipe(\n    prompt,\n    max_new_tokens=256,  # Max tokens to generate\n    do_sample=True,       # Enable sampling for randomness\n    top_k=1,             # Limit sampling to top 1 token\n)\n\n# Extract the assistant's response (the text after \"English:\")\nassistant_response = outputs[0][\"generated_text\"].split(\"<|im_start|>assistant\")[-1].strip()\n\n# Print only the assistant's response\nprint(assistant_response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:11:44.992428Z","iopub.execute_input":"2025-02-17T14:11:44.992771Z","iopub.status.idle":"2025-02-17T14:11:47.539082Z","shell.execute_reply.started":"2025-02-17T14:11:44.992734Z","shell.execute_reply":"2025-02-17T14:11:47.537985Z"}},"outputs":[{"name":"stdout","text":"A group of researchers has launched a new model for translation-related tasks.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# I asked chatgpt help, dw I just asked it to incorporate the docu code\n# Define your messages and translation task\nmessages = [\n    {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n]\n\n# Define the text you want to translate\ntext = \"Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\"\n\n# Combine the messages and text in a column-wise format\nprompt = pipe.tokenizer.apply_chat_template(\n    messages + [{\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"}],\n    tokenize=False,\n    add_generation_prompt=True\n)\n\n# Generate the translation with Top-k sampling\noutputs = pipe(\n    prompt,\n    max_new_tokens=256,  # Max tokens to generate\n    do_sample=True,       # Enable sampling for randomness\n    top_k=50,             # Limit sampling to top 50 tokens\n)\n\n# Extract the assistant's response (everything after the last \"English:\")\nassistant_response = outputs[0][\"generated_text\"].split(\"English:\")[-1].strip()\n\n# Clean up any additional prompts or formatting that might appear after the response\nassistant_response = assistant_response.split(\"\\n\")[0].strip()\n\n# Print only the assistant's response\nprint(assistant_response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:09:33.815840Z","iopub.execute_input":"2025-02-17T14:09:33.816200Z","iopub.status.idle":"2025-02-17T14:09:36.514674Z","shell.execute_reply.started":"2025-02-17T14:09:33.816165Z","shell.execute_reply":"2025-02-17T14:09:36.513800Z"}},"outputs":[{"name":"stdout","text":"<|im_end|>\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Sus the experimenter\n# You guys are prolly not reading these\n\ntext = '''\n\n<|im_start|>user\nTranslate the following text from Italian into English.<|im_end|>\n<|im_start|>user\nItaliano: Un gruppo di ricercatori ha lanciato un nuovo modello per compiti legati alla traduzione.\nEnglish:<|im_end|>\n<|im_start|>assistant\n A group of researchers has launched a new model for translation-related tasks. Blah Blah testing sheep.\n'''\n \n\n# Extract the assistant's response (the text after \"English:\")\nop = text.split(\"<|im_start|>assistant\")[-1].strip() \n\n# Print only the assistant's response\nprint(op)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:13:15.913471Z","iopub.execute_input":"2025-02-17T14:13:15.913806Z","iopub.status.idle":"2025-02-17T14:13:15.918198Z","shell.execute_reply.started":"2025-02-17T14:13:15.913784Z","shell.execute_reply":"2025-02-17T14:13:15.917187Z"}},"outputs":[{"name":"stdout","text":"A group of researchers has launched a new model for translation-related tasks. Blah Blah testing sheep.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n\n# Function to handle the translation for a single row\ndef translate_row(text):\n    # Define the prompt format for translation\n    messages = [\n        {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n        {\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"},\n    ]\n\n    # Combine messages and create the input prompt\n    prompt = pipe.tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    # Generate the translation with Top-k sampling\n    outputs = pipe(\n        prompt,\n        max_new_tokens=256,  # Max tokens to generate\n        do_sample=True,       # Enable sampling for randomness\n        top_k=1,              # Limit sampling to top 1 token\n    )\n\n    # Extract the assistant's response (the text after \"English:\")\n    assistant_response = outputs[0][\"generated_text\"].split(\"<|im_start|>assistant\")[-1].strip() # Split I figured so yay to that\n\n    return assistant_response\n\n# Function to translate the entire dataset in batches\ndef translate_dataset_in_batches(df, batch_size=2):\n    translated_texts = []\n\n    # Loop through the dataset in batches\n    for i in tqdm(range(0, len(df), batch_size)):\n        batch = df.iloc[i:i + batch_size]\n        \n        # Translate each row in the batch\n        batch_translations = batch[\"text\"].apply(translate_row).tolist()\n        \n        # Add the translated texts to the result list\n        translated_texts.extend(batch_translations)\n\n    # Add the translated texts to the DataFrame\n    df[\"translated_text\"] = translated_texts\n    return df\n\n# Translate the dataset\ntranslated_df = translate_dataset_in_batches(df, batch_size=2)\n\n# Print the translated DataFrame\nprint(translated_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n# Assuming you've already loaded the model as 'pipe'\n# And your data is already loaded as 'data' with a 'Content' column to translate\n\n# Function to handle the translation for a single row\ndef translate_row(text):\n    # Define the prompt format for translation\n    messages = [\n        {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n        {\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"},\n    ]\n\n    # Combine messages and create the input prompt\n    prompt = pipe.tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    # Generate the translation with Top-k sampling\n    outputs = pipe(\n        prompt,\n        do_sample=True,       # Enable sampling for randomness\n        top_k=1,              # Limit sampling to top 1 token\n    )\n\n    # Extract the assistant's response (the text after \"English:\")\n    assistant_response = outputs[0][\"generated_text\"].split(\"<|im_start|>assistant\")[-1].strip()\n\n    return assistant_response\n\n# Function to translate the entire dataset in batches\ndef translate_dataset_in_batches(data, batch_size=2):\n    translated_texts = []\n\n    # Loop through the dataset in batches\n    for i in tqdm(range(0, len(data), batch_size)):\n        batch = data.iloc[i:i + batch_size]\n        \n        # Translate each row in the batch from 'Content' column\n        batch_translations = batch[\"Content\"].apply(translate_row).tolist()\n        \n        # Add the translated texts to the result list\n        translated_texts.extend(batch_translations)\n\n    # Add the translated texts to the DataFrame\n    data[\"Translated\"] = translated_texts\n    return data\n\n# Translate the dataset\ntranslated_data = translate_dataset_in_batches(data, batch_size=20) # It was 2 before my bad \n\n# Print the translated DataFrame\nprint(translated_data[['Content', 'Translated']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:18:10.040989Z","iopub.execute_input":"2025-02-17T14:18:10.041287Z","iopub.status.idle":"2025-02-17T14:47:47.715335Z","shell.execute_reply.started":"2025-02-17T14:18:10.041266Z","shell.execute_reply":"2025-02-17T14:47:47.714223Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 240/240 [29:37<00:00,  7.41s/it]","output_type":"stream"},{"name":"stdout","text":"                                               Content  \\\n0    Dopo aver hackerato la tv di Stato sostituendo...   \n1    #flowers #lovers\\nFate l'amore non fate la gue...   \n2    Se solo tutti mostrassimo più amore e comprens...   \n3    Chi sono i soldati che vediamo nei video? Sono...   \n4    Non credevo che #Salvini potesse peggiorare la...   \n..                                                 ...   \n475  Se scrivo che la signora #Zelensky sarebbe sta...   \n476  #Zelensky e sua moglie #OlenaZelenska hanno ac...   \n477  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n478  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n479  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n\n                                            Translated  \n0    After hacking the state TV by replacing propag...  \n1    #flowers #lovers\\nMake love, not war.\\nMarc Ch...  \n2    If only we all showed more love and understand...  \n3    Who are the soldiers we see in the videos? Are...  \n4    I didn't think #Salvini could make his positio...  \n..                                                 ...  \n475  If I write that Mrs. #Zelensky was spotted in ...  \n476  #Zelensky and his wife #OlenaZelenska bought a...  \n477        EVERYONE UNITED AGAINST DRAGHI\\nAGAINST WAR  \n478        UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST  \n479        UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST  \n\n[480 rows x 2 columns]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"translated_data.to_csv('Translated_Unbabel.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:47:47.716837Z","iopub.execute_input":"2025-02-17T14:47:47.717204Z","iopub.status.idle":"2025-02-17T14:47:47.729502Z","shell.execute_reply.started":"2025-02-17T14:47:47.717179Z","shell.execute_reply":"2025-02-17T14:47:47.728385Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"translated_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:49:28.266360Z","iopub.execute_input":"2025-02-17T14:49:28.266728Z","iopub.status.idle":"2025-02-17T14:49:28.281775Z","shell.execute_reply.started":"2025-02-17T14:49:28.266698Z","shell.execute_reply":"2025-02-17T14:49:28.280568Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0                   ID  \\\n0               0             0           0  1498022438398877704   \n1               1             2           2  1497887473862467584   \n2               2             3           3  1497838543619645441   \n3               3             4           4  1497639979534667783   \n4               4             5           5  1497624763396546561   \n..            ...           ...         ...                  ...   \n475           475           718         718  1538486694701408256   \n476           476           721         721  1538254178413322241   \n477           477           722         722  1537840889749458946   \n478           478           726         726  1535923240710946816   \n479           479           727         727  1535893068108513280   \n\n                                                   URL   Type  Label  \\\n0    https://twitter.com/manuela_carloni/status/149...  tweet      1   \n1    https://twitter.com/barbarameletto/status/1497...  tweet      2   \n2    https://twitter.com/_dani_ta_6/status/14978385...  tweet      2   \n3    https://twitter.com/GabrieleGranato/status/149...  tweet      2   \n4    https://twitter.com/nonleggerlo/status/1497624...  tweet      1   \n..                                                 ...    ...    ...   \n475  https://twitter.com/fratotolo2/status/15384866...  tweet      1   \n476  https://twitter.com/104Pierpa/status/153825417...  tweet      0   \n477  https://twitter.com/PartitComunista/status/153...  tweet      2   \n478  https://twitter.com/PartitComunista/status/153...  tweet      2   \n479  https://twitter.com/PartitComunista/status/153...  tweet      2   \n\n                                               Content  \\\n0    Dopo aver hackerato la tv di Stato sostituendo...   \n1    #flowers #lovers\\nFate l'amore non fate la gue...   \n2    Se solo tutti mostrassimo più amore e comprens...   \n3    Chi sono i soldati che vediamo nei video? Sono...   \n4    Non credevo che #Salvini potesse peggiorare la...   \n..                                                 ...   \n475  Se scrivo che la signora #Zelensky sarebbe sta...   \n476  #Zelensky e sua moglie #OlenaZelenska hanno ac...   \n477  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n478  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n479  TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...   \n\n                  Image_Name  \\\n0    1498022438398877704.jpg   \n1    1497887473862467584.jpg   \n2    1497838543619645441.jpg   \n3    1497639979534667783.jpg   \n4    1497624763396546561.jpg   \n..                       ...   \n475  1538486694701408256.jpg   \n476  1538254178413322241.jpg   \n477  1537840889749458946.jpg   \n478  1535923240710946816.jpg   \n479  1535893068108513280.jpg   \n\n                                            Translated  \n0    After hacking the state TV by replacing propag...  \n1    #flowers #lovers\\nMake love, not war.\\nMarc Ch...  \n2    If only we all showed more love and understand...  \n3    Who are the soldiers we see in the videos? Are...  \n4    I didn't think #Salvini could make his positio...  \n..                                                 ...  \n475  If I write that Mrs. #Zelensky was spotted in ...  \n476  #Zelensky and his wife #OlenaZelenska bought a...  \n477        EVERYONE UNITED AGAINST DRAGHI\\nAGAINST WAR  \n478        UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST  \n479        UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST  \n\n[480 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>URL</th>\n      <th>Type</th>\n      <th>Label</th>\n      <th>Content</th>\n      <th>Image_Name</th>\n      <th>Translated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1498022438398877704</td>\n      <td>https://twitter.com/manuela_carloni/status/149...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Dopo aver hackerato la tv di Stato sostituendo...</td>\n      <td>1498022438398877704.jpg</td>\n      <td>After hacking the state TV by replacing propag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1497887473862467584</td>\n      <td>https://twitter.com/barbarameletto/status/1497...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>#flowers #lovers\\nFate l'amore non fate la gue...</td>\n      <td>1497887473862467584.jpg</td>\n      <td>#flowers #lovers\\nMake love, not war.\\nMarc Ch...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1497838543619645441</td>\n      <td>https://twitter.com/_dani_ta_6/status/14978385...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Se solo tutti mostrassimo più amore e comprens...</td>\n      <td>1497838543619645441.jpg</td>\n      <td>If only we all showed more love and understand...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1497639979534667783</td>\n      <td>https://twitter.com/GabrieleGranato/status/149...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>Chi sono i soldati che vediamo nei video? Sono...</td>\n      <td>1497639979534667783.jpg</td>\n      <td>Who are the soldiers we see in the videos? Are...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1497624763396546561</td>\n      <td>https://twitter.com/nonleggerlo/status/1497624...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Non credevo che #Salvini potesse peggiorare la...</td>\n      <td>1497624763396546561.jpg</td>\n      <td>I didn't think #Salvini could make his positio...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>475</td>\n      <td>718</td>\n      <td>718</td>\n      <td>1538486694701408256</td>\n      <td>https://twitter.com/fratotolo2/status/15384866...</td>\n      <td>tweet</td>\n      <td>1</td>\n      <td>Se scrivo che la signora #Zelensky sarebbe sta...</td>\n      <td>1538486694701408256.jpg</td>\n      <td>If I write that Mrs. #Zelensky was spotted in ...</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>476</td>\n      <td>721</td>\n      <td>721</td>\n      <td>1538254178413322241</td>\n      <td>https://twitter.com/104Pierpa/status/153825417...</td>\n      <td>tweet</td>\n      <td>0</td>\n      <td>#Zelensky e sua moglie #OlenaZelenska hanno ac...</td>\n      <td>1538254178413322241.jpg</td>\n      <td>#Zelensky and his wife #OlenaZelenska bought a...</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>477</td>\n      <td>722</td>\n      <td>722</td>\n      <td>1537840889749458946</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1537840889749458946.jpg</td>\n      <td>EVERYONE UNITED AGAINST DRAGHI\\nAGAINST WAR</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>478</td>\n      <td>726</td>\n      <td>726</td>\n      <td>1535923240710946816</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535923240710946816.jpg</td>\n      <td>UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>479</td>\n      <td>727</td>\n      <td>727</td>\n      <td>1535893068108513280</td>\n      <td>https://twitter.com/PartitComunista/status/153...</td>\n      <td>tweet</td>\n      <td>2</td>\n      <td>TUTTI UNITI CONTRO DRAGHI\\nCONTRO LA GUERRA\\nC...</td>\n      <td>1535893068108513280.jpg</td>\n      <td>UNITED AGAINST DRAGHI\\nAGAINST WAR\\nAGAINST</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n# Assuming you've already loaded the model as 'pipe'\n# And your data is already loaded as 'data' with a 'Content' column to translate\n\n# Function to handle the translation for a single row\ndef translate_row(text):\n    # Define the prompt format for translation\n    messages = [\n        {\"role\": \"user\", \"content\": \"Translate the following text from Italian into English.\"},\n        {\"role\": \"user\", \"content\": f\"Italiano: {text}\\nEnglish:\"},\n    ]\n\n    # Combine messages and create the input prompt\n    prompt = pipe.tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    # Generate the translation with Top-k sampling\n    outputs = pipe(\n        prompt,\n        do_sample=True,       # Enable sampling for randomness\n        top_k=1,              # Limit sampling to top 1 token\n    )\n\n    # Extract the assistant's response (the text after \"English:\")\n    assistant_response = outputs[0][\"generated_text\"].split(\"<|im_start|>assistant\")[-1].strip()\n\n    return assistant_response\n\n# Function to translate the entire dataset in batches\ndef translate_dataset_in_batches(data, batch_size=2):\n    translated_texts = []\n\n    # Loop through the dataset in batches\n    for i in tqdm(range(0, len(data), batch_size)):\n        batch = data.iloc[i:i + batch_size]\n        \n        # Translate each row in the batch from 'Content' column\n        batch_translations = batch[\"Content\"].apply(translate_row).tolist()\n        \n        # Add the translated texts to the result list\n        translated_texts.extend(batch_translations)\n\n    # Add the translated texts to the DataFrame\n    data[\"Translated\"] = translated_texts\n    return data\n\n# Translate the dataset\ntranslated_data = translate_dataset_in_batches(data, batch_size=20) # It was 2 before my bad \n\n# Print the translated DataFrame\nprint(translated_data[['Content', 'Translated']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:52:40.043651Z","iopub.execute_input":"2025-02-17T14:52:40.044089Z"}},"outputs":[{"name":"stderr","text":" 50%|█████     | 12/24 [14:52<14:59, 74.97s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"translated_data.to_csv('Translated_Unbabel.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}